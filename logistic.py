from google.colab import drive
import pandas as pd
import numpy as np

drive.mount('/content/drive')


path = '/content/drive/My Drive/WA_Fn-UseC_-Telco-Customer-Churn (1) .csv'

df=pd.read_csv(path)
df.head()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['Churn'] = le.fit_transform(df['Churn'])
print(df['Churn'].value_counts())

import matplotlib.pyplot as plt
import seaborn as sns
plt.scatter(df['OnlineSecurity'],df['Churn'])
plt.show()

# Convert 'TotalCharges' to numeric, coercing errors (non-numeric values) to NaN
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# Drop rows where 'TotalCharges' became NaN after conversion
df.dropna(subset=['TotalCharges'], inplace=True)

# Define features (X) and target (y)
X = df[['tenure', 'TotalCharges', 'MonthlyCharges']]
y = df['Churn']

print(f"Shape of X: {x.shape}")
print(f"Shape of y: {y.shape}")

import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,classification_report
import matplotlib.pyplot as plt

X_tain,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)
model=LogisticRegression()
model.fit(X_tain,y_train)
y_pred=model.predict(X_test)
print("predict",y_pred)

acc=accuracy_score(y_test,y_pred)
print("accuracy",acc)
print("Classification",classification_report(y_test,y_pred))

mean_total_charges = X['TotalCharges'].mean()
mean_monthly_charges = X['MonthlyCharges'].mean()

x_range_tenure = np.linspace(X['tenure'].min(), X['tenure'].max(), 100)

X_for_prob_prediction = pd.DataFrame({
    'tenure': x_range_tenure,
    'TotalCharges': [mean_total_charges] * len(x_range_tenure),
    'MonthlyCharges': [mean_monthly_charges] * len(x_range_tenure)
})

y_prob = model.predict_proba(X_for_prob_prediction)[:, 1]

plt.scatter(X['tenure'], y, color="red", label="Actual Data", alpha=0.5)
plt.plot(x_range_tenure, y_prob, color="blue", label="Predicted Probability")

plt.xlabel('Tenure')
plt.ylabel('Churn / Predicted Probability')
plt.title('Churn Probability vs. Tenure (other features held at mean)')
plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", cm)